{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Latex to PreText Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes for latex conventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* multi-line verbs should have no blank lines between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # regular expressions\n",
    "from os import walk # directory listings\n",
    "from tkinter import Tk     # from tkinter import Tk for Python 3.x\n",
    "from tkinter.filedialog import askopenfilename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "#### Helper Functions\n",
    "\n",
    "def add_header(book_id,book_title,files_lines = []):\n",
    "    new_lines = files_lines.copy()\n",
    "    new_lines.append('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    new_lines.append('\\n')\n",
    "    new_lines.append('<pretext xmlns:xi=\"http://www.w3.org/2001/XInclude\" xml:lang=\"en-US\">\\n')\n",
    "    new_lines.append('\\n')\n",
    "    new_lines.append('<xi:include href=\"./sections/bookinfo.xml\" />\\n')\n",
    "    new_lines.append('\\n')\n",
    "    new_lines.append('<book xml:id=\"'+ book_id + '\">\\n')\n",
    "    new_lines.append('<title>' + book_title + '</title>\\n')\n",
    "    new_lines.append('\\n')\n",
    "    \n",
    "    return new_lines\n",
    "\n",
    "def add_footer(files_lines):\n",
    "    new_lines = files_lines.copy()\n",
    "    new_lines.append('</book>\\n')\n",
    "    new_lines.append('\\n')\n",
    "    new_lines.append('</pretext>\\n')\n",
    "    \n",
    "    return new_lines\n",
    "\n",
    "def get_line_type(line):\n",
    "    # is line a comment?\n",
    "    if re.search(r'^%', line) != None or re.search('^<!--', line) != None:\n",
    "        return 'comment'\n",
    "    # is line a blank line?\n",
    "    if line == '\\n':\n",
    "        return 'blank'\n",
    "    # is line the beginning of an example?\n",
    "    if re.search(r'\\\\begin\\{Example\\}', line) != None or re.search(r'\\<example xml:', line) != None:\n",
    "        return 'b_example'\n",
    "    # is line the end of an example?\n",
    "    if re.search(r'\\\\end\\{Example\\}', line) != None or re.search(r'\\</example\\>', line) != None:\n",
    "        return 'e_example'\n",
    "    # is line a section header?\n",
    "    if re.search(r'\\\\section', line) != None or re.search(r'\\<section xml:', line) != None:\n",
    "        return 'section'\n",
    "    # is line a section footer?\n",
    "    if re.search(r'\\</section\\>', line) != None:\n",
    "        return 'e_section'\n",
    "    # is line a standalone \\index?\n",
    "    if re.search(r'^\\\\index', line) != None:\n",
    "        return 'index'\n",
    "    # is line a single-line \\verb?\n",
    "    if re.search(r'^\\\\verb\\|.*?\\|$', line) != None:\n",
    "        return 'single_verb'\n",
    "    # is line a single-line \\verb with text?\n",
    "    if re.search(r'^\\\\verb\\|.*?\\|\\s*\\w+[\\\\\\\\$]', line) != None:\n",
    "        return 'single_verb_w_text'\n",
    "    # is line a multi-line \\verb?\n",
    "    if re.search(r'^\\\\verb\\|.*\\|$', line) != None or re.search(r'^\\\\verb\\|.*\\|\\s*[\\\\\\\\$]', line) != None:\n",
    "        return 'multi_verb'\n",
    "    elif re.search(r'\\\\ps \\\\verb', line) != None:\n",
    "        return 'in_verb'\n",
    "    # is line a <pre>?\n",
    "    if re.search(r'^.*\\<pre\\>.*\\</pre\\>.+$|^.+\\<pre\\>.*\\</pre\\>.*$', line) != None:\n",
    "        return 'inline_pre'\n",
    "    # is line a <p>?\n",
    "    if re.search(r'\\<p\\>', line) != None:\n",
    "        return 'b_paragraph'\n",
    "    # is line a <\\p>?\n",
    "    if re.search(r'\\</p\\>', line) != None:\n",
    "        return 'e_paragraph'\n",
    "    # is line a <pre>?\n",
    "    if re.search(r'^\\<pre\\>', line) != None:\n",
    "        return 'b_pre'\n",
    "    # is line a <\\pre>?\n",
    "    if re.search(r'\\</pre\\>$', line) != None:\n",
    "        return 'e_pre'\n",
    "    \n",
    "    # is line a <sidebyside>?\n",
    "    if re.search(r'^\\<sidebyside', line) != None:\n",
    "        return 'b_sidebyside'\n",
    "    # is line a <\\sidebyside>?\n",
    "    if re.search(r'\\</sidebyside\\>$', line) != None:\n",
    "        return 'e_sidebyside'\n",
    "    \n",
    "    # is line a <program>?\n",
    "    if re.search(r'^\\<program', line) != None:\n",
    "        return 'b_program'\n",
    "    # is line a <\\program>?\n",
    "    if re.search(r'\\</program\\>$', line) != None:\n",
    "        return 'e_program'\n",
    "    \n",
    "    # is line a <input>?\n",
    "    if re.search(r'^\\<input', line) != None:\n",
    "        return 'b_input'\n",
    "    # is line a <\\input>?\n",
    "    if re.search(r'\\</input\\>$', line) != None:\n",
    "        return 'e_input'\n",
    "    \n",
    "    # is line a <title>?\n",
    "    if re.search(r'\\<title\\>', line) != None:\n",
    "        return 'title'\n",
    "    # is line a subsection header?\n",
    "    if re.search(r'\\\\noindent \\\\large \\\\textsf\\{', line) != None or re.search(r'\\<paragraphs xml:', line) != None or re.search(r'\\\\subsection\\{', line) != None:\n",
    "        return 'b_subsection'\n",
    "    # is line a subsection footer?\n",
    "    if re.search(r'\\</paragraphs\\>', line) != None or re.search(r'\\</paragraphs/>', line) != None:\n",
    "        return 'e_subsection'\n",
    "    # is line a display math \\[ header?\n",
    "    if re.search(r'^\\s*\\\\\\[\\s*$', line) != None or re.search(r'\\<md\\>', line) != None:\n",
    "        return 'b_dmath'\n",
    "    # is line a display math \\] footer?\n",
    "    if re.search(r'^\\s*\\\\\\]\\s*$', line) != None or re.search(r'\\</md\\>', line) != None:\n",
    "        return 'e_dmath'# is line none of the above?\n",
    "    # is line a math array header?\n",
    "    if re.search(r'\\\\begin\\{array', line) != None:\n",
    "        return 'b_array'\n",
    "    # is line a math array footer?\n",
    "    if re.search(r'\\\\end\\{array', line) != None:\n",
    "        return 'e_array'\n",
    "    # is line a math align header?\n",
    "    if re.search(r'\\\\begin\\{align', line) != None:\n",
    "        return 'b_align'\n",
    "    # is line a math align footer?\n",
    "    if re.search(r'\\\\end\\{align', line) != None:\n",
    "        return 'e_align'\n",
    "    # is line an table header?\n",
    "    if re.search(r'\\\\begin\\{table', line) != None or re.search(r'\\<table', line) != None:\n",
    "        return 'b_table'\n",
    "    # is line an table footer?\n",
    "    if re.search(r'\\\\end\\{table', line) != None or re.search(r'\\</table', line) != None:\n",
    "        return 'e_table'\n",
    "    # is line an tabular header?\n",
    "    if re.search(r'\\\\begin\\{tabular', line) != None or re.search(r'\\<tabular', line) != None:\n",
    "        return 'b_tabular'\n",
    "    # is line an tabular footer?\n",
    "    if re.search(r'\\\\end\\{tabular', line) != None or re.search(r'\\</tabular', line) != None:\n",
    "        return 'e_tabular'\n",
    "    # is line an enumerate header?\n",
    "    if re.search(r'\\\\begin\\{enumerate', line) != None:\n",
    "        return 'b_enumerate'\n",
    "    # is line an enumerate footer?\n",
    "    if re.search(r'\\\\end\\{enumerate', line) != None:\n",
    "        return 'e_enumerate'\n",
    "    # is line an itemize header?\n",
    "    if re.search(r'\\\\begin\\{itemize', line) != None:\n",
    "        return 'b_itemize'\n",
    "    # is line an itemize footer?\n",
    "    if re.search(r'\\\\end\\{itemize', line) != None:\n",
    "        return 'e_itemize'\n",
    "    # is line an ordered list header?\n",
    "    if re.search(r'\\<ol\\>', line) != None:\n",
    "        return 'b_olist'\n",
    "    # is line an ordered list footer?\n",
    "    if re.search(r'\\</ol\\>', line) != None:\n",
    "        return 'e_olist'\n",
    "    # is line an unordered list header?\n",
    "    if re.search(r'\\<ul\\>', line) != None:\n",
    "        return 'b_ulist'\n",
    "    # is line an unordered list footer?\n",
    "    if re.search(r'\\</ul\\>', line) != None:\n",
    "        return 'e_ulist'\n",
    "    # is line an \\item[?]?\n",
    "    if re.search(r'\\\\item\\[.*?\\]', line) != None:\n",
    "        return 'item_w_arg'\n",
    "    # is line an \\item?\n",
    "    if re.search(r'\\\\item', line) != None:\n",
    "        return 'item'\n",
    "    # is line an <row>?\n",
    "    if re.search(r'\\<row', line) != None:\n",
    "        return 'b_row'\n",
    "    # is line an </row>?\n",
    "    if re.search(r'\\</row', line) != None:\n",
    "        return 'e_row'\n",
    "    # is line an <li>?\n",
    "    if re.search(r'\\<li\\>', line) != None:\n",
    "        return 'b_item'\n",
    "    # is line an </li>?\n",
    "    if re.search(r'\\</li\\>', line) != None:\n",
    "        return 'e_item'\n",
    "    return 'other' # is line none of the above?\n",
    "\n",
    "# get tab depth\n",
    "def get_tab_depth(line):\n",
    "    start_tabs = re.findall(\"^\\t+\", line)\n",
    "    if start_tabs == []:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(re.findall(\"\\t\", start_tabs[0]))\n",
    "\n",
    "def is_troy_chapter(lines):\n",
    "    for line in lines[:5]:\n",
    "        if re.search(r'\\\\settikzpagecorners', line) != None:\n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parser Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "#### Parser Functions\n",
    "\n",
    "#### Section Parser\n",
    "\n",
    "# - Splits the sections into independent xml files\n",
    "# - Converts the section syntax\n",
    "\n",
    "def get_section_info(line,n,chpt,saveto):\n",
    "    # get title and reference label\n",
    "    section_match1 = re.search(r'\\\\section\\{\\s*(.*)?\\s*:\\s*(.*)?\\}\\\\label\\{\\s*sec:(.*)?\\s*\\}', line)\n",
    "    section_match2 = re.search(r'\\\\section\\{\\s*(.*)?\\s*\\}\\\\label\\{\\s*(.*)?\\s*\\}', line)\n",
    "    section_match3 = re.search(r'\\\\section\\{\\s*(.*)?\\s*\\}', line)\n",
    "    if section_match1 != None:\n",
    "        return { 'title' : section_match1.group(2), \n",
    "                 'label' : 'sec-' + section_match1.group(3), \n",
    "                 'filename' : saveto + 'sec-' + f\"{chpt:02d}\" + \"_\" + f\"{n:02d}\" + '-' + section_match1.group(3).lower() + '.xml'}\n",
    "    elif section_match2 != None:\n",
    "        return { 'title' : section_match2.group(1), \n",
    "                 'label' : 'sec-' + section_match2.group(2), \n",
    "                 'filename' : saveto + 'sec-' + f\"{chpt:02d}\" + \"_\" + f\"{n:02d}\" + '-' + section_match2.group(2).lower() + '.xml'}\n",
    "    else:\n",
    "        generic_label = re.sub(r'\\s','_',section_match3.group(1).lower())\n",
    "        return { 'title' : section_match3.group(1), \n",
    "                 'label' : 'sec-' + generic_label,\n",
    "                 'filename' : saveto + 'sec-' + f\"{chpt:02d}\" + \"_\" + f\"{n:02d}\" + '-' + generic_label + '.xml'}\n",
    "        \n",
    "# Important charaters that must be done first!\n",
    "def parse_exceptional_chars(lines):\n",
    "    converted_lines = []\n",
    "    for line in lines:\n",
    "        # ampersand char\n",
    "        line = re.sub(r'\\\\\\&|\\&', '&amp;', line)\n",
    "        # < ;\n",
    "        line = re.sub(r'\\<', '&lt;', line)\n",
    "        # > ;\n",
    "        line = re.sub(r'\\>', '&gt;', line)\n",
    "        \n",
    "        converted_lines.append(line)\n",
    "    \n",
    "    return converted_lines\n",
    "\n",
    "# Description: separates each latex section into a new pretext section\n",
    "# Inputs:\n",
    "#   1. lines (list) contains all lines of latex file.\n",
    "# Outputs:\n",
    "#   1. pretext_sections (list of dictionaries) \n",
    "def split_sections(lines, chpt = '', saveto = []):\n",
    "    # critical replacements\n",
    "    lines = parse_exceptional_chars(lines)\n",
    "    # list of filenames that are split\n",
    "    filenames = []\n",
    "    section_number = 1\n",
    "    # add section header lines\n",
    "    pretext_header = []\n",
    "    pretext_header.append('<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\\n')\n",
    "    pretext_header.append('\\n')\n",
    "    pretext_header.append('<!--********************************************************************-->\\n')\n",
    "    pretext_header.append('\\n')\n",
    "    pretext_lines = pretext_header.copy()\n",
    "    for line in lines:\n",
    "        line_type = get_line_type(line)\n",
    "        # check for section\n",
    "        if line_type == 'section':\n",
    "            if section_number == 1: # first section found\n",
    "                section_info = get_section_info(line,section_number,chpt,saveto)\n",
    "                pretext_file = open(section_info['filename'], \"w+\")\n",
    "                filenames.append(section_info['filename'])\n",
    "                section_number += 1\n",
    "            else: # end of current section\n",
    "                pretext_lines.append('</section>\\n\\n') # end last section\n",
    "                pretext_file.writelines(pretext_lines)\n",
    "                pretext_file.close()\n",
    "                pretext_lines = pretext_header.copy()\n",
    "                section_info = get_section_info(line,section_number,chpt,saveto)\n",
    "                section_number += 1\n",
    "                filenames.append(section_info['filename'])\n",
    "                pretext_file = open(section_info['filename'], \"w+\")\n",
    "                \n",
    "            pretext_lines.append('<section xml:id=\"' + section_info['label'] + '\" xmlns:xi=\"http://www.w3.org/2001/XInclude\">\\n')\n",
    "            pretext_lines.append('<title>' + section_info['title'] + '</title>')\n",
    "            pretext_lines.append('\\n')\n",
    "        else:\n",
    "            pretext_lines.append(line)\n",
    "    \n",
    "    pretext_lines.append('\\n')\n",
    "    pretext_lines.append('</section>\\n\\n') # end last section\n",
    "    pretext_file.writelines(pretext_lines)\n",
    "    pretext_file.close()\n",
    "    return filenames\n",
    "                \n",
    "\n",
    "\n",
    "#### Verbose Parser\n",
    "\n",
    "# - Converts all latex = \\verb environments to pretext = \\<pre\\> environments\n",
    "\n",
    "def convert_verb_line(line,type = 'multi_verb'):\n",
    "    if type == 'multi_verb':\n",
    "        line = re.sub(r'\\\\\\\\', \"\\n\", line) # line break character\n",
    "        line = re.sub(r'\\\\ps', \"\\t\", line) # tab character\n",
    "        line = re.sub(r'\\\\verb\\|(.*?)\\|\\n', \"\\t\\g<1>\\n\", line)\n",
    "        line = re.sub(r'\\\\verb\\|(.*?)\\|', \"\\t\\g<1>\\n\", line)\n",
    "    elif type == 'single_verb':\n",
    "        line = re.sub(r'^\\\\verb\\|(.*?)\\|$', '\\g<1>', line)\n",
    "        line = re.sub(r'\\\\\\\\', '', line) # \n",
    "    return line\n",
    "\n",
    "def parse_verbs(lines):\n",
    "    in_multi_line_verb = False\n",
    "    in_verb = False\n",
    "    converted_lines = []\n",
    "    # first line\n",
    "    this_line = lines[0]\n",
    "    for next_line in lines[1:]:\n",
    "        this_line_type = get_line_type(this_line)\n",
    "        next_line_type = get_line_type(next_line)\n",
    "        #converted_lines.append(get_line_type(this_line))\n",
    "        # check for multi-line verb\n",
    "        if in_multi_line_verb: # continue multi-line verb\n",
    "            # convert this line\n",
    "            converted_lines.append(convert_verb_line(this_line[:-1]))\n",
    "            # check for verb end\n",
    "            if next_line_type not in ['in_verb','multi_verb']: # end multi-line verb\n",
    "                #converted_lines.append('</pre>\\n')\n",
    "                #converted_lines.append('</p>\\n')\n",
    "                \n",
    "                converted_lines.append('</input>\\n')\n",
    "                converted_lines.append('</program>\\n')\n",
    "                converted_lines.append('</sidebyside>\\n')\n",
    "                in_multi_line_verb = False\n",
    "        # check this line for a single-verb\n",
    "        elif this_line_type == 'single_verb' and next_line_type != 'in_verb':\n",
    "            #converted_lines.append('<p>\\n')\n",
    "            #converted_lines.append('<c>\\n')\n",
    "            \n",
    "            converted_lines.append('<sidebyside width=\"100%\">\\n')\n",
    "            converted_lines.append('<program language=\"MATLAB\">\\n')\n",
    "            converted_lines.append('<input>\\n')\n",
    "            converted_lines.append(convert_verb_line(this_line, 'single_verb'))\n",
    "            converted_lines.append('</input>\\n')\n",
    "            converted_lines.append('</program>\\n')\n",
    "            converted_lines.append('</sidebyside>\\n')\n",
    "            \n",
    "            #converted_lines.append('</c>\\n')\n",
    "            #converted_lines.append('</p>\\n')\n",
    "        elif this_line_type == 'multi_verb' or (this_line_type == 'single_verb' and next_line_type == 'in_verb'):\n",
    "            in_multi_line_verb = True\n",
    "            #converted_lines.append('<p>\\n')\n",
    "            #converted_lines.append('<pre>\\n')\n",
    "            \n",
    "            converted_lines.append('<sidebyside width=\"100%\">\\n')\n",
    "            converted_lines.append('<program language=\"MATLAB\">\\n')\n",
    "            converted_lines.append('<input>\\n')\n",
    "            converted_lines.append(convert_verb_line(this_line[:-1])) \n",
    "        elif this_line_type == 'single_verb_w_text' and next_line_type in ['other','single_verb_w_text']:\n",
    "            converted_lines.append('<p>\\n')\n",
    "            converted_lines.append(convert_verb_line(this_line, 'single_verb'))\n",
    "            converted_lines.append('</p>\\n')\n",
    "            in_verb = True\n",
    "        elif this_line_type == 'other' and in_verb:\n",
    "            converted_lines.append('<p>\\n')\n",
    "            converted_lines.append(convert_verb_line(this_line, 'single_verb'))\n",
    "            converted_lines.append('</p>\\n')\n",
    "            in_verb = False\n",
    "        else:\n",
    "            converted_lines.append(this_line)\n",
    "        this_line = next_line\n",
    "    \n",
    "    converted_lines.append(next_line)\n",
    "    return converted_lines\n",
    "\n",
    "\n",
    "#### Example Parser\n",
    "\n",
    "# - Converts all latex = \\begin{example} environments to pretext = \\<example\\> environments\n",
    "\n",
    "def get_example_info(line):\n",
    "    # get label and 2nd argument\n",
    "    ex_label_match = re.search(r'\\\\begin\\{Example\\}\\{(.*)?\\}\\{(.*)?\\}', line)\n",
    "    label = ex_label_match.group(1)\n",
    "    title = ex_label_match.group(2)\n",
    "    return { 'label' : label, 'title' : title }\n",
    "    \n",
    "def parse_examples(lines):\n",
    "    in_example = False\n",
    "    converted_lines = []\n",
    "    for line in lines:\n",
    "        line_type = get_line_type(line)\n",
    "        #converted_lines.append(get_line_type(line))\n",
    "        # check for new example\n",
    "        if line_type == 'b_example':\n",
    "            in_example = True\n",
    "            example_info = get_example_info(line)\n",
    "            converted_lines.append('<example xml:id=\"' + example_info['label'] + '\"><p/>\\n')\n",
    "            converted_lines.append('<title><em>' + example_info['title'] + '</em></title><p/>\\n')\n",
    "        # check for end of example\n",
    "        elif line_type == 'e_example':\n",
    "            in_example = False\n",
    "            converted_lines.append('</example>\\n')  \n",
    "        else:\n",
    "            converted_lines.append(line)\n",
    "    \n",
    "    return converted_lines\n",
    "\n",
    "#### Paragraph Parser\n",
    "\n",
    "def parse_paragraphs(lines):\n",
    "    in_paragraph = False\n",
    "    converted_lines = []\n",
    "    prev_line = lines[0]\n",
    "    for this_line in lines[1:]:\n",
    "        prev_line_type = get_line_type(prev_line)\n",
    "        this_line_type = get_line_type(this_line)\n",
    "        \n",
    "        #converted_lines.append(get_line_type(this_line))\n",
    "        # check for beginning of paragraph \n",
    "        if prev_line_type == 'blank' and this_line_type == 'other':\n",
    "            in_paragraph = True\n",
    "            converted_lines.append('<p>\\n')\n",
    "        elif prev_line_type == 'other' and this_line_type in ['blank','e_example','b_paragraph'] and in_paragraph:\n",
    "            in_paragraph = False\n",
    "            converted_lines.append('</p>\\n')\n",
    "        \n",
    "        converted_lines.append(this_line)\n",
    "        prev_line = this_line\n",
    "    \n",
    "    converted_lines.append(this_line)\n",
    "    \n",
    "    return converted_lines\n",
    "\n",
    "#### Subsection Parser\n",
    "\n",
    "def get_subsection_info(line):\n",
    "    # get label and 2nd argument\n",
    "    header_match1 = re.search(r'\\\\noindent \\\\large \\\\textsf\\{\\\\underline\\{(.*?)\\}: (.*?)\\} \\\\normalsize', line)\n",
    "    header_match2 = re.search(r'\\\\noindent \\\\large \\\\textsf\\{\\\\textbf\\{(.*?)\\}\\} \\\\normalsize', line)\n",
    "    header_match3 = re.search(r'\\\\subsection\\{\\s*(.*?)\\s*\\}', line)\n",
    "    if header_match1 != None:\n",
    "        title = header_match1.group(1) + ': ' + header_match1.group(2)\n",
    "        label = re.sub(r'\\s','-',header_match1.group(2))\n",
    "        label = re.sub(r':','',label)\n",
    "        kind = 1\n",
    "    elif header_match2 != None:\n",
    "        title = '<c>' + header_match2.group(1) + '</c>'\n",
    "        label = re.sub(r'\\s','-',header_match2.group(1))\n",
    "        label = re.sub('\\s*\\(.*?\\)\\s*','',label)\n",
    "        label = re.sub(r':','',label)\n",
    "        kind = 2\n",
    "    elif header_match3 != None:\n",
    "        title = header_match3.group(1)\n",
    "        label = re.sub(r'\\s','-',header_match3.group(1).lower())\n",
    "        label = re.sub(r':','',label)\n",
    "        kind = 3\n",
    "    else:\n",
    "        title = 'FUCK'\n",
    "        label = 'SHIT'\n",
    "        kind = 4\n",
    "\n",
    "    return { 'title' : title, 'label' : label , 'kind' : kind}\n",
    "    \n",
    "def parse_subsections(lines):\n",
    "    subsection_number = 1\n",
    "    converted_lines = []\n",
    "    for line in lines:\n",
    "        line_type = get_line_type(line)\n",
    "        # check for new subsection\n",
    "        if line_type == 'b_subsection':\n",
    "            if subsection_number == 1: # first subsection found\n",
    "                subsection_info = get_subsection_info(line)\n",
    "                subsection_number += 1\n",
    "            else: # end of current subsection\n",
    "                converted_lines.append('</paragraphs>\\n') # end subsection\n",
    "                converted_lines.append('\\n')\n",
    "                subsection_info = get_subsection_info(line)\n",
    "                subsection_number += 1\n",
    "                \n",
    "            converted_lines.append('<paragraphs xml:id=\"' + subsection_info['label'] + '\">\\n')\n",
    "            converted_lines.append('<title>' + subsection_info['title'] + '</title><p/>\\n')\n",
    "            converted_lines.append('\\n')\n",
    "        elif line_type == 'e_section' and subsection_number > 1:\n",
    "            converted_lines.append('</paragraphs>\\n') # end final subsection\n",
    "            converted_lines.append('\\n')\n",
    "            converted_lines.append(line)\n",
    "        else:\n",
    "            converted_lines.append(line)\n",
    "    \n",
    "    return converted_lines\n",
    "\n",
    "\n",
    "#### Display Math Parser\n",
    "\n",
    "def parse_display_math(lines):\n",
    "    in_math = False\n",
    "    in_array = False\n",
    "    in_align = False\n",
    "    converted_lines = []\n",
    "    for line in lines:\n",
    "        line_type = get_line_type(line)\n",
    "        # check for display math start\n",
    "        #converted_lines.append(get_line_type(line))\n",
    "        if line_type == 'b_dmath':\n",
    "            in_math = True\n",
    "            converted_lines.append(re.sub(r'\\\\\\[', r'<md>', line))\n",
    "        # check for display math end\n",
    "        elif line_type == 'e_dmath':\n",
    "            in_math = False\n",
    "            converted_lines.append(re.sub(r'\\\\\\]', r'</md>', line))\n",
    "        # check for align env start\n",
    "        elif line_type == 'b_align' and not(in_math):\n",
    "            in_align = True\n",
    "            converted_lines.append(re.sub(r'\\\\begin\\{align\\**\\}', r'<md>', line))\n",
    "        # check for align env end\n",
    "        elif line_type == 'e_align' and not(in_math):\n",
    "            in_align = False\n",
    "            converted_lines.append(re.sub(r'\\\\end\\{align\\**\\}', r'</md>', line))\n",
    "        elif in_math or in_align:\n",
    "            if line_type == 'b_array':\n",
    "                in_array = True\n",
    "            elif line_type == 'e_array':\n",
    "                in_array = False\n",
    "            elif in_array or in_align:\n",
    "                # convert & to \\amp\n",
    "                #temp_line = re.sub(r'&', r'\\\\amp', line)\n",
    "                line = re.sub(r'\\\\\\\\', r'', line)\n",
    "                # wrap in <mrow>\n",
    "                converted_lines.append(re.sub(r'^(.*)$', '<mrow>\\g<1></mrow>', line))\n",
    "            elif re.search(r'\\\\\\]$',line) != None:\n",
    "                converted_lines.append(re.sub(r'\\\\\\]$', '', line))\n",
    "                converted_lines.append('</md>\\n')\n",
    "                in_math = False\n",
    "        else:\n",
    "            converted_lines.append(line)\n",
    "\n",
    "    return converted_lines\n",
    "\n",
    "def get_list_items(lines,k=0):\n",
    "    item_list = []\n",
    "    item_list.append('<ol>\\n')\n",
    "    in_item = False\n",
    "    while(k < len(lines)):\n",
    "        line = lines[k]\n",
    "        line_type = get_line_type(line)\n",
    "        if line_type in ['b_enumerate','b_itemize']:\n",
    "            [k,nested_lines] = get_list_items(lines,k+1)\n",
    "            item_list = item_list + nested_lines\n",
    "        elif line_type in ['e_enumerate','e_itemize']:\n",
    "            item_list.append('</li>\\n')\n",
    "            item_list.append('</ol>\\n')\n",
    "            return [k,item_list]\n",
    "        elif line_type in ['item','item_w_arg']:\n",
    "            if in_item:\n",
    "                item_list.append('</li>\\n')\n",
    "            else:\n",
    "                in_item = True\n",
    "                \n",
    "            item_list.append('<li>\\n')\n",
    "            if line_type == 'item':\n",
    "                item_list.append(re.sub(r'.*\\\\item\\s*(.*)$','\\g<1>', line))\n",
    "            elif line_type == 'item_w_arg':\n",
    "                item_list.append(re.sub(r'.*\\\\item\\[.*?\\]\\s*(.*)$','\\g<1>', line))\n",
    "        else:\n",
    "            if line_type != 'blank':\n",
    "                item_list.append(line)\n",
    "        k += 1\n",
    "\n",
    "def parse_lists(lines):\n",
    "    converted_lines = []\n",
    "    k=0\n",
    "    while k < len(lines):\n",
    "        line = lines[k]\n",
    "        line_type = get_line_type(line)\n",
    "        #converted_lines.append(get_line_type(line))\n",
    "        if line_type in ['b_enumerate','b_itemize']:\n",
    "            [k,nested_lines] = get_list_items(lines,k+1)\n",
    "            converted_lines = converted_lines + nested_lines\n",
    "        else:\n",
    "            converted_lines.append(line)\n",
    "        k += 1\n",
    "    return converted_lines\n",
    "\n",
    "def get_table_info(lines,k=0):\n",
    "    \n",
    "    for k in range(k,len(lines)):\n",
    "        line = lines[k]\n",
    "        line_type = get_line_type(line)\n",
    "        if line_type == 'b_tabular':\n",
    "            [k,tabular] = parse_tabulars(lines,k)\n",
    "        elif line_type == 'e_table':\n",
    "            return k, { 'label' : label, 'caption' : caption, 'tabular': tabular}\n",
    "            \n",
    "        caption_match = re.search(r'\\\\caption\\{\\s*(.*?)\\s*\\}', line)\n",
    "        if caption_match != None:\n",
    "            caption = caption_match.group(1)\n",
    "        label_match = re.search(r'\\\\label\\{\\s*(.*?)\\s*\\}', line)\n",
    "        if label_match != None:\n",
    "            label = label_match.group(1)\n",
    "\n",
    "def parse_tables(lines):\n",
    "    in_table = False\n",
    "    converted_lines = []\n",
    "    k = 0\n",
    "    while k < len(lines):\n",
    "        line = lines[k]\n",
    "        line_type = get_line_type(line)\n",
    "        #converted_lines.append(get_line_type(line))\n",
    "        # check for new table\n",
    "        if line_type == 'b_table':\n",
    "            in_table = True\n",
    "            [k, table_info] = get_table_info(lines,k+1)\n",
    "            converted_lines.append('\\n')\n",
    "            converted_lines.append('<table xml:id=\"' + table_info['label'] + '\">\\n')\n",
    "            converted_lines.append('<caption>' + table_info['caption'] + '</caption>\\n')\n",
    "            converted_lines = converted_lines + table_info['tabular']\n",
    "            converted_lines.append('</table>') \n",
    "        else:\n",
    "            converted_lines.append(line)\n",
    "        k += 1\n",
    "    \n",
    "    return converted_lines\n",
    "\n",
    "def get_tabular_info(line):\n",
    "    tabular_match = re.search(r'\\\\begin\\{tabular\\}\\{(.*)?\\}', line)\n",
    "    properties = tabular_match.group(1)\n",
    "    properties_info = re.findall(r\"c|r|l|p\\{.*\\}|\\|\", properties)\n",
    "    vertical_lines = []\n",
    "    col_alignment = []\n",
    "    align_translator = {'c':'center','l':'left','r':'right','p':'left'}\n",
    "    for p in properties_info:\n",
    "        if p == '|':\n",
    "            vertical_lines.append(True)\n",
    "        else:    \n",
    "            vertical_lines.append(False)\n",
    "            col_alignment.append(align_translator[p[0]])\n",
    "            \n",
    "    return {'col_alignment' : col_alignment, 'vertical_lines' : vertical_lines}\n",
    "            \n",
    "def parse_tabulars(lines,k=0):\n",
    "    in_tabular = False\n",
    "    tabular_lines = []\n",
    "    for k in range(k,len(lines)):\n",
    "        line = lines[k]\n",
    "        line_type = get_line_type(line)\n",
    "        #converted_lines.append(get_line_type(line))\n",
    "        # check for new tabular\n",
    "        if line_type == 'b_tabular':\n",
    "            in_tabular = True\n",
    "            tabular_info = get_tabular_info(line)\n",
    "            tabular_lines.append('<tabular>\\n')\n",
    "        # check for end of example\n",
    "        elif line_type == 'e_tabular':\n",
    "            in_tabular = False\n",
    "            tabular_lines.append('</tabular>\\n') \n",
    "            return k, tabular_lines\n",
    "        else:\n",
    "            row_items = re.split(r\"\\s*&amp;\\s*\",line)\n",
    "            if re.search(r'\\\\hline',row_items[-1]) != None:\n",
    "                tabular_lines.append('<row bottom=\"minor\">\\n')\n",
    "            else:\n",
    "                tabular_lines.append('<row>\\n')\n",
    "\n",
    "            for i in range(len(row_items)):\n",
    "                item = re.sub(r'^\\s*','',row_items[i])\n",
    "                item = re.sub(r'\\s*\\n\\s*','',item)\n",
    "                item = re.sub(r'\\s*\\\\hline\\s*','',item)\n",
    "                if i == len(row_items) and tabular_info['vertical_lines'][i] and tabular_info['vertical_lines'][i+1]:\n",
    "                    tabular_lines.append('<cell left=\"minor\" right=\"minor\" halign=\"' + tabular_info['col_alignment'][i] + '\">' + item + '</cell>')\n",
    "                elif tabular_info['vertical_lines'][i]:\n",
    "                    tabular_lines.append('<cell left=\"minor\" halign=\"' + tabular_info['col_alignment'][i] + '\">' + item + '</cell>')\n",
    "                else:\n",
    "                    tabular_lines.append('<cell halign=\"' + tabular_info['col_alignment'][i] + '\">' + item + '</cell>')\n",
    "                tabular_lines.append('\\n')\n",
    "            tabular_lines.append('</row>\\n')\n",
    "\n",
    "\n",
    "#### General Parser (Find & Replace, Ignore, Delete)\n",
    "\n",
    "# Converts:\n",
    "# \n",
    "# - inline math: $\\$$ $\\to$ \\<m\\>\n",
    "# - boldface text: \\textbf $\\to$ \\<term\\>\n",
    "# - italic text: \\it $\\to$ \\<em\\>\n",
    "# - double left single quotes: `` $\\to$ \"\n",
    "# - double right single quotes: '' $\\to$ \"\n",
    "# - inline \\verb: \\verb $\\to$ \\<c\\>\n",
    "# \n",
    "# Ignores:\n",
    "# \n",
    "# - %\\settikzpagecorners\n",
    "# \n",
    "# Removes:\n",
    "# \n",
    "# - ?\n",
    "\n",
    "def parse_general_top_priority(lines):\n",
    "    \n",
    "    converted_lines = []\n",
    "    for line in lines:\n",
    "        \n",
    "        # Conversion items ------------------------------\n",
    "        # color element\n",
    "        line = re.sub(r'\\{\\\\color\\{.*?\\}\\s*(.*?)\\}', '\\g<1>', line)\n",
    "        \n",
    "        converted_lines.append(line)\n",
    "        \n",
    "    return converted_lines\n",
    "\n",
    "def parse_general_low_priority(lines):\n",
    "    \n",
    "    ignore_line = False\n",
    "    converted_lines = []\n",
    "    for l in range(len(lines)):\n",
    "        \n",
    "        line = lines[l]\n",
    "        # Ignore items ------------------------------\n",
    "        if re.search(r'%\\\\settikzpagecorners', line) != None:\n",
    "            ignore_line = True \n",
    "        elif re.search(r'\\\\index', line) != None:\n",
    "            ignore_line = True\n",
    "\n",
    "        # Conversion items ------------------------------\n",
    "        # inline math\n",
    "        line = re.sub(r'\\$(.*?)\\$', '<m>\\g<1></m>', line)\n",
    "        # boldface text\n",
    "        line = re.sub(r'\\\\textbf\\{(.*?)\\}', '<term>\\g<1></term>', line)\n",
    "        # italic text\n",
    "        line = re.sub(r'\\{\\\\it (.*?)\\}', '<em>\\g<1></em>', line)\n",
    "        # double left single quotes\n",
    "        line = re.sub(r'``', '\"', line)\n",
    "        # double right single quotes\n",
    "        line = re.sub(r\"''\",'\"', line)\n",
    "        # inline \\verb\n",
    "        line = re.sub(r'\\\\verb\\|(.*?)\\|', '<c>\\g<1></c>', line)\n",
    "        # comments\n",
    "        line = re.sub(r'^\\s*%(.*)', '<!-- \\g<1> -->', line)\n",
    "        # line break character\n",
    "        line = re.sub(r'\\\\\\\\', '\\n', line) \n",
    "        # \\noindent\n",
    "        line = re.sub(r'\\\\noindent', '', line) \n",
    "        # \\newpage\n",
    "        line = re.sub(r'\\\\newpage', '', line) \n",
    "        # \\textquotesingle\n",
    "        line = re.sub(r'\\|\\\\textquotesingle', \"'|\", line) \n",
    "        line = re.sub(r'\\</c\\>\\\\textquotesingle', \"'</c>\", line) \n",
    "        line = re.sub(r'\\\\textquotesingle', \"'\", line) \n",
    "        # remove space before and after ^\n",
    "        line = re.sub(r'\\s\\^\\s', \"^\", line)\n",
    "        # remove space before and after ^\n",
    "        line = re.sub(r'\\|\\\\\\^\\{\\}\\\\verb\\|', \"^\", line)\n",
    "        line = re.sub(r'\\</c\\>\\\\\\^\\{\\}\\<c\\>', \"^\", line)\n",
    "        # inline ^ to <c>\n",
    "        line = re.sub(r'\\\\\\^\\{\\}', \"<c>^</c>\", line)\n",
    "        # add space after ;\n",
    "        line = re.sub(r';', \"; \", line)\n",
    "        # remove artifact whitespace after &amp;, &lt; and &gt;\n",
    "        line = re.sub(r'\\&amp; ', '&amp;', line)\n",
    "        line = re.sub(r'\\&lt; ', '&lt;', line)\n",
    "        line = re.sub(r'\\&gt; ', '&gt;', line)\n",
    "        # \\cour element\n",
    "        line = re.sub(r'\\\\cour\\{(.*?)\\}', '\\g<1>', line)\n",
    "        # \\quad element\n",
    "        line = re.sub(r'\\\\quad', '', line)\n",
    "        # \\qquad element\n",
    "        line = re.sub(r'\\\\qquad', '', line)\n",
    "        # \\po tab element\n",
    "        line = re.sub(r'\\\\po', '\\t', line)\n",
    "        \n",
    "        if ignore_line:\n",
    "            ignore_line = False\n",
    "        else:\n",
    "            converted_lines.append(line)\n",
    "        \n",
    "    return converted_lines\n",
    "\n",
    "def remove_double_blank_lines(lines):\n",
    "    \n",
    "    converted_lines = []\n",
    "    this_line = lines[0]\n",
    "    for next_line in lines[1:]:\n",
    "        \n",
    "        this_line_type = get_line_type(this_line)\n",
    "        next_line_type = get_line_type(next_line)\n",
    "        if not(this_line_type == 'blank' and next_line_type == 'blank'):\n",
    "            converted_lines.append(this_line)\n",
    "        this_line = next_line\n",
    "        \n",
    "    converted_lines.append(next_line)        \n",
    "    return converted_lines\n",
    "\n",
    "def move_section_intro(lines):\n",
    "    in_intro = False\n",
    "    converted_lines = []\n",
    "    for k in range(len(lines)):\n",
    "        line = lines[k]\n",
    "        line_type = get_line_type(line)\n",
    "        if line[:5] == r'<!--*':\n",
    "            intro_start = k+1\n",
    "        elif re.search(r'\\<section xml:', line) != None:\n",
    "            intro_end = k\n",
    "            break\n",
    "            \n",
    "    converted_lines = lines[:intro_start] + ['\\n'] + lines[intro_end:intro_end+2] + lines[intro_start:intro_end] + lines[intro_end+2:]\n",
    "        \n",
    "    return converted_lines\n",
    "\n",
    "def fix_indentations(lines):\n",
    "    tab_depth = 0\n",
    "    converted_lines = []\n",
    "    for line in lines:\n",
    "        line_type = get_line_type(line)\n",
    "        #converted_lines.append(get_line_type(line))\n",
    "        if line_type == 'blank':\n",
    "            converted_lines.append(line)\n",
    "        elif line_type == 'title':\n",
    "            converted_lines.append('\\t'*tab_depth + line)\n",
    "            tab_depth += 1\n",
    "        elif line_type in ['b_paragraph',\n",
    "                           'b_example',\n",
    "                           'b_pre','b_dmath',\n",
    "                           'b_olist',\n",
    "                           'b_ulist',\n",
    "                           'b_item',\n",
    "                           'b_table',\n",
    "                           'b_tabular',\n",
    "                           'b_sidebyside',\n",
    "                           'b_program',\n",
    "                           'b_input',\n",
    "                           'b_row'\n",
    "                          ]:\n",
    "            converted_lines.append('\\t'*tab_depth + line)\n",
    "            tab_depth += 1\n",
    "        elif line_type in ['e_section',\n",
    "                           'e_subsection',\n",
    "                           'e_paragraph',\n",
    "                           'e_example',\n",
    "                           'e_pre',\n",
    "                           'e_dmath',\n",
    "                           'e_olist',\n",
    "                           'e_ulist',\n",
    "                           'e_item',\n",
    "                           'e_table',\n",
    "                           'e_tabular',\n",
    "                           'e_sidebyside',\n",
    "                           'e_program',\n",
    "                           'e_input',\n",
    "                           'e_row'\n",
    "                          ]:\n",
    "            tab_depth -= 1\n",
    "            converted_lines.append('\\t'*tab_depth + line)\n",
    "        else:\n",
    "            converted_lines.append('\\t'*tab_depth + line)\n",
    "\n",
    "    return converted_lines\n",
    "\n",
    "def fix_p_tags(lines):\n",
    "    in_paragraph = False\n",
    "    converted_lines = []\n",
    "    for line in lines:\n",
    "        line_type = get_line_type(line)\n",
    "        \n",
    "        if line_type == 'b_paragraph':              # beginning of paragraph\n",
    "            in_paragraph = True\n",
    "        elif line_type == 'e_paragraph':            # end of paragraph\n",
    "            in_paragraph = False\n",
    "        elif in_paragraph and line_type == 'blank': # in paragraph and blank found\n",
    "            converted_lines.append('</p>\\n')   # add </p>\n",
    "            in_paragraph = False\n",
    "            \n",
    "        converted_lines.append(line)\n",
    "        \n",
    "    return converted_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tex_root = 'C:/Users/gcox0/Google Drive/1--MATLAB_textbook/MA110 MA310 SP21/'\n",
    "main_tex_name = 'MA110_310_Text.tex'\n",
    "xml_root = 'C:/Users/gcox0/Google Drive/1--MATLAB_textbook/4--master_copy/MATLAB-ebook/'\n",
    "book_title = 'MATLAB BOOK'\n",
    "\n",
    "# get filenames from chapter location\n",
    "tex_chapter_root = tex_root + 'chapters/'\n",
    "pretext_section_root = xml_root + 'sections/'\n",
    "filenames = next(walk(tex_chapter_root), (None, None, []))[2]  # [] if no file\n",
    "        \n",
    "# get chapter content\n",
    "chapter_files = []\n",
    "for file in filenames:\n",
    "    if re.search('^\\d\\d_MATLAB',file) != None:\n",
    "        chapter_files.append(file)\n",
    "\n",
    "# pick a chapter \n",
    "chpt_num = 2\n",
    "sect_num = 2\n",
    "    \n",
    "# Load and read each chapter\n",
    "chapter_name = chapter_files[chpt_num - 1]\n",
    "chapter_path = tex_chapter_root + chapter_name\n",
    "\n",
    "print(chapter_name)\n",
    "\n",
    "chapter_latex_file = open(chapter_path,\"r\")\n",
    "chapter_latex_lines = chapter_latex_file.readlines()\n",
    "chapter_latex_file.close()\n",
    "\n",
    "chpt_sections = split_sections(chapter_latex_lines, chpt_num, pretext_section_root)\n",
    "section_path = chpt_sections[sect_num - 1]\n",
    "section_path_split = re.split('/',section_path)\n",
    "section_file = section_path_split[-1]\n",
    "    \n",
    "print(section_file)\n",
    "\n",
    "section_latex_file = open(section_path, \"r\")\n",
    "section_latex_lines = section_latex_file.readlines()\n",
    "section_latex_file.close()\n",
    "\n",
    "section_latex_lines = move_section_intro(section_latex_lines)\n",
    "section_latex_lines = parse_general_top_priority(section_latex_lines)\n",
    "section_latex_lines = parse_subsections(section_latex_lines)\n",
    "section_latex_lines = parse_examples(section_latex_lines)\n",
    "section_latex_lines = parse_verbs(section_latex_lines)\n",
    "section_latex_lines = parse_display_math(section_latex_lines)\n",
    "section_latex_lines = parse_general_low_priority(section_latex_lines)\n",
    "section_latex_lines = remove_double_blank_lines(section_latex_lines)\n",
    "section_latex_lines = parse_paragraphs(section_latex_lines)\n",
    "section_latex_lines = fix_p_tags(section_latex_lines)\n",
    "section_latex_lines = parse_lists(section_latex_lines)\n",
    "section_latex_lines = parse_tables(section_latex_lines)\n",
    "section_latex_lines = fix_indentations(section_latex_lines)\n",
    "\n",
    "#get_list_items\n",
    "\n",
    "section_pretext_file = open(section_path, \"w+\")\n",
    "section_pretext_file.writelines(section_latex_lines)\n",
    "section_pretext_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitch = [6,7,8,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitch.append(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 7, 8, 8, 4]\n"
     ]
    }
   ],
   "source": [
    "print(bitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitch.remove(bitch[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shit = '“'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(r'“',shit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
